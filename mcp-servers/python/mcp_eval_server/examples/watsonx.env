# IBM Watsonx.ai Configuration Example
# ====================================

# Gateway Configuration
MCP_GATEWAY_URL=http://localhost:4444
MCPGATEWAY_BEARER_TOKEN=your-jwt-token-here

# IBM Watsonx.ai Provider
LLM_PROVIDER=watsonx

# IBM Watsonx.ai Settings
WATSONX_API_KEY=your-watsonx-api-key
WATSONX_PROJECT_ID=your-project-id
WATSONX_URL=https://us-south.ml.cloud.ibm.com

# Model Configuration
DEFAULT_MODEL=llama-3.1-70b

# Agent Settings
TEMPERATURE=0.7
MAX_ITERATIONS=10
STREAMING_ENABLED=false  # Watsonx.ai may not support streaming

# Performance Settings
REQUEST_TIMEOUT=60  # Watsonx.ai can be slower
MAX_TOKENS=2000

# Tool Configuration (optional)
TOOLS=

# Debug Mode
DEBUG_MODE=false

# IBM Watsonx.ai Model Options:
# - meta-llama/llama-3-1-70b-instruct    # Most capable Llama model
# - ibm/granite-3-0-8b-instruct          # IBM's Granite model
# - mistralai/mixtral-8x7b-instruct-v01   # Mixtral model
# - meta-llama/llama-3-1-8b-instruct     # Smaller Llama model
# - ibm/granite-3-0-2b-instruct          # Smallest Granite model

# Get API key from: https://cloud.ibm.com/
# Documentation: https://ibm.github.io/watsonx-ai-python-sdk/
